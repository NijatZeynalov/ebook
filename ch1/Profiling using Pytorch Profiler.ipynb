{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dfd3076-3bfa-4041-a257-10e30012fc4d",
   "metadata": {},
   "source": [
    "# Step 1: Baseline Model (AlexNet adapted for MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84910993-c76b-4232-b053-95d64ff464b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Baseline Training Time: 208.57s\n",
      "Baseline Inference Time: 4.3859s | Accuracy: 99.01%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seed and device\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize MNIST to match AlexNet input size\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoader (baseline)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1000)\n",
    "\n",
    "# Define model: Modified AlexNet for grayscale MNIST images\n",
    "class AlexNetMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = AlexNetMNIST().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Timing functions\n",
    "def train(model, loader, epochs=5):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return time.time() - start_time\n",
    "\n",
    "def inference(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    acc = correct / len(loader.dataset)\n",
    "    return acc, time.time() - start_time\n",
    "\n",
    "# Baseline Training/Inference\n",
    "baseline_train_time = train(model, train_loader)\n",
    "baseline_acc, baseline_inference_time = inference(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c893a089-e102-4536-8fd5-e8a4c1624720",
   "metadata": {},
   "source": [
    "# Baseline Training/Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7403ae6a-efce-4349-a447-db4f893c09cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Training Time: 208.57s\n",
      "Baseline Inference Time: 4.3859s | Accuracy: 99.01%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Baseline Training Time: {baseline_train_time:.2f}s\")\n",
    "print(f\"Baseline Inference Time: {baseline_inference_time:.4f}s | Accuracy: {baseline_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3da9e7-4229-4e94-802e-ed005cfa2872",
   "metadata": {},
   "source": [
    "# Step 2: Profiling the Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55645df-7a25-4232-86bc-0d8da5babdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Profiling Baseline Model...\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         2.21%     952.073us        63.48%      27.341ms      13.671ms       0.000us         0.00%      14.602ms       7.301ms        -512 b      -6.13 Mb      -5.37 Mb     -12.25 Mb             2  \n",
      "                                             train_step         7.55%       3.250ms        12.95%       5.579ms       5.579ms       0.000us         0.00%      14.113ms      14.113ms           0 b           0 b     219.06 Mb     120.12 Mb             1  \n",
      "                           Optimizer.step#Adadelta.step         0.00%       0.000us         0.00%       0.000us       0.000us      11.790ms        30.55%      11.790ms      11.790ms           0 b           0 b           0 b           0 b             1  \n",
      "                           Optimizer.step#Adadelta.step         1.22%     526.043us         2.44%       1.051ms       1.051ms       0.000us         0.00%      11.684ms      11.684ms           0 b          -4 b           0 b    -435.91 Mb             1  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       5.138ms        13.31%       5.138ms     428.137us           0 b           0 b           0 b           0 b            12  \n",
      "void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8...         0.00%       0.000us         0.00%       0.000us       0.000us       3.649ms         9.46%       3.649ms     243.280us           0 b           0 b           0 b           0 b            15  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.528ms         9.14%       3.528ms     293.982us           0 b           0 b           0 b           0 b            12  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.510ms         9.09%       3.510ms     292.492us           0 b           0 b           0 b           0 b            12  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       3.460ms         8.96%       3.460ms     288.304us           0 b           0 b           0 b           0 b            12  \n",
      "                                    aten::_foreach_mul_         0.12%      53.775us         0.28%     122.276us      40.759us       3.035ms         7.87%       3.035ms       1.012ms           0 b           0 b           0 b           0 b             3  \n",
      "autograd::engine::evaluate_function: ConvolutionBack...         0.12%      52.965us         2.47%       1.062ms     212.418us       0.000us         0.00%       2.665ms     533.084us           0 b           0 b     -35.61 Mb     -69.34 Mb             5  \n",
      "                                   ConvolutionBackward0         0.05%      21.455us         2.33%       1.002ms     200.495us       0.000us         0.00%       2.665ms     533.084us           0 b           0 b      33.73 Mb           0 b             5  \n",
      "                             aten::convolution_backward         0.75%     321.930us         2.28%     981.020us     196.204us       2.465ms         6.39%       2.665ms     533.084us           0 b           0 b      33.73 Mb      22.86 Mb             5  \n",
      "                                             train_step         0.00%       0.000us         0.00%       0.000us       0.000us       2.570ms         6.66%       2.570ms       2.570ms           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       2.567ms         6.65%       2.567ms     427.851us           0 b           0 b           0 b           0 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 43.071ms\n",
      "Self CUDA time total: 38.593ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def profile_model():\n",
    "    model.train()\n",
    "    with profile(\n",
    "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True,\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3)\n",
    "    ) as prof:\n",
    "        for step, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with record_function(\"train_step\"):\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            prof.step()\n",
    "\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=15))\n",
    "\n",
    "print(\"\\nProfiling Baseline Model...\")\n",
    "profile_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea51812-7eb9-454c-95ba-132310a11e25",
   "metadata": {},
   "source": [
    "## Profiling Results Summary\n",
    "\n",
    "| Operator / Event | CUDA Time (ms) | % of Total |\n",
    "|------------------|----------------|------------|\n",
    "| `Optimizer.step#Adadelta.step` | ~11.790 | 30.55% |\n",
    "| Multi-tensor ops (`multi_tensor_applier`) | ~5.138–3.460 | ~25% total |\n",
    "| `aten::convolution_backward` | ~2.465 | 6.39% |\n",
    "| `cutlass::Kernel...` (likely forward convs) | ~3.649 | 9.46% |\n",
    "\n",
    "1. **Adadelta Optimizer dominates GPU time (30%)**\n",
    "   - This is a known issue with Adadelta, it has heavy internal computation. We will do optimizer switch: `Adadelta` → `AdamW`\n",
    "2. **Multi-tensor operations take ~25%**\n",
    "   - These are likely from optimizer updates or gradient manipulations.\n",
    "3. **Convolution backward pass (~6.4%)**\n",
    "   - Expected, but not the main bottleneck here.\n",
    "4. **Forward convolution kernel (~9.5%)**\n",
    "   - Also expected; AlexNet is convolution-heavy.\n",
    "\n",
    "\n",
    "We also will change:\n",
    "\n",
    "Mixed Precision Training -  Reduces memory usage and speeds up computation.\n",
    "\n",
    "Classifier Head Simplification - original large fully connected layers caused slowdowns. Replaced with smaller FC layers.\n",
    "\n",
    "\n",
    "DataLoader Improvements - Speed up data loading and reduce host-device transfer bottlenecks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24dba0f-eb3e-4038-9137-a186f928fbc0",
   "metadata": {},
   "source": [
    "# Step 3: Optimized Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2855a9d-2884-4892-b7c4-590e9027ff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Training Optimized Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3977/957607441.py:86: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/tmp/ipykernel_3977/957607441.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/tmp/ipykernel_3977/957607441.py:112: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import inspect\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Resize MNIST to fit AlexNet input size\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Optimized DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=1000,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# Define AlexNet with adaptive classifier head\n",
    "class AlexNetMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 6 * 6, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = AlexNetMNIST().to(device)\n",
    "\n",
    "# Use AdamW with fused kernels if available\n",
    "use_fused = 'fused' in inspect.signature(optim.AdamW).parameters\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, fused=use_fused) if use_fused else optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# GradScaler for mixed precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Training function\n",
    "def train_optimized(model, loader, epochs=5):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "    return time.time() - start_time\n",
    "\n",
    "# Inference function\n",
    "def inference_optimized(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    acc = correct / len(loader.dataset)\n",
    "    return acc, time.time() - start_time\n",
    "\n",
    "print(\"\\nTraining Optimized Model...\")\n",
    "optimized_train_time = train_optimized(model, train_loader)\n",
    "optimized_acc, optimized_inference_time = inference_optimized(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d9093-92be-4b21-a5f4-2259d8058727",
   "metadata": {},
   "source": [
    "# Run optimized training & inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7afc3d5-d42f-4827-bdbe-ecbe01d78f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Training Time: 208.57s | Accuracy: 99.01%\n",
      "Optimized Training Time: 42.91s | Accuracy: 99.44%\n",
      "Speedup: 4.86x\n",
      "\n",
      "Baseline Inference Time: 4.3859s\n",
      "Optimized Inference Time: 1.4929s\n",
      "Speedup: 2.94x\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nBaseline Training Time: {baseline_train_time:.2f}s | Accuracy: {baseline_acc*100:.2f}%\")\n",
    "print(f\"Optimized Training Time: {optimized_train_time:.2f}s | Accuracy: {optimized_acc*100:.2f}%\")\n",
    "print(f\"Speedup: {baseline_train_time / optimized_train_time:.2f}x\")\n",
    "\n",
    "print(f\"\\nBaseline Inference Time: {baseline_inference_time:.4f}s\")\n",
    "print(f\"Optimized Inference Time: {optimized_inference_time:.4f}s\")\n",
    "print(f\"Speedup: {baseline_inference_time / optimized_inference_time:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
